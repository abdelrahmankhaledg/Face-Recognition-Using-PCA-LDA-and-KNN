{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y-TvncWHJ0C"
      },
      "source": [
        "# Report Link\n",
        "https://docs.google.com/document/d/1OzHshf46L-8EXjkod2YAW2c4bVLP6Dbp0NyYaKk64io/edit?usp=sharing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcr0mnCr040q"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwmZhTTUDrvM",
        "outputId": "96257d2d-78ad-45fb-f0e7-fbe01833921b"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a1118ce4adcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 135\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report,accuracy_score,ConfusionMatrixDisplay\n",
        "from google.colab import drive\n",
        "import gc\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy.core.fromnumeric import size\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw7beiHs1MLo"
      },
      "source": [
        "# Generation of Data Matrix and Splitting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_OnGEHb2WT9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import PIL\n",
        "an_image = PIL.Image.open(\"/content/drive/MyDrive/prassignment1/s1/1.pgm\")\n",
        "image_sequence = an_image.getdata() \n",
        "image_array = np.array(image_sequence)\n",
        "data_matrix = np.full([10305,1],None)\n",
        "for i in range(40):\n",
        "  num_of_file=str(i+1)\n",
        "  path=\"/content/drive/MyDrive/prassignment1/s{}\".format(num_of_file)\n",
        "  for j in range(10):\n",
        "    num_of_image=str(j+1)\n",
        "    full_path=path+\"/\"+num_of_image+\".pgm\"\n",
        "    an_image = PIL.Image.open(full_path)\n",
        "    image_sequence = an_image.getdata()\n",
        "    image_array = np.array(image_sequence)\n",
        "    image_array_labeled = np.insert(image_array,0,i,axis=0)\n",
        "    data_matrix=np.c_[data_matrix,image_array_labeled]\n",
        "    \n",
        "\n",
        "data_matrix=data_matrix[:,1:]\n",
        "data_matrix=np.transpose(data_matrix)\n",
        "even_data_matrix=np.full([1,10305],None)\n",
        "odd_data_matrix=np.full([1,10305],None)\n",
        "for i in range(400):\n",
        "  if i%2==0:\n",
        "    even_data_matrix=np.append(even_data_matrix,[data_matrix[i]],axis=0)\n",
        "  else:\n",
        "    odd_data_matrix=np.append(odd_data_matrix,[data_matrix[i]],axis=0)\n",
        "even_data_matrix=np.delete(even_data_matrix,0,0)\n",
        "odd_data_matrix=np.delete(odd_data_matrix,0,0)\n",
        "thirty_data_matrix=np.full([1,10305],None)\n",
        "seventy_data_matrix=np.full([1,10305],None)\n",
        "for i in range(40):\n",
        "  for j in range(10):\n",
        "    if j>6:\n",
        "      thirty_data_matrix=np.append(thirty_data_matrix,[data_matrix[i*10+j]],axis=0)\n",
        "    else:\n",
        "      seventy_data_matrix=np.append(seventy_data_matrix,[data_matrix[i*10+j]],axis=0)\n",
        "thirty_data_matrix=np.delete(thirty_data_matrix,0,0)\n",
        "seventy_data_matrix=np.delete(seventy_data_matrix,0,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEwhYoVCOzH_"
      },
      "source": [
        "#PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByVpo17F6BVF"
      },
      "source": [
        "## Data formatting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iz0oPbVPiXog"
      },
      "outputs": [],
      "source": [
        "dataset = odd_data_matrix[:,1:10305]\n",
        "print(dataset.shape)\n",
        "alpha_values = [0.8,0.85,0.9,0.95]\n",
        "\n",
        "\n",
        "\n",
        "print(dataset)\n",
        "\n",
        "\n",
        "# center data\n",
        "print(dataset.mean(axis = 0).shape)\n",
        "centered_ds = dataset - dataset.mean(axis = 0)\n",
        "print(centered_ds.shape)\n",
        "\n",
        "\n",
        "# get covariance matrix\n",
        "cov_matrix = np.cov(centered_ds.astype(float).T,ddof=0)\n",
        "print(cov_matrix.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW0Fiw9Yr-9K"
      },
      "source": [
        "## Computing eigen-values & eigen-vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ihoTqrBUjv4A"
      },
      "outputs": [],
      "source": [
        "# compute eigen values and eigen vectors\n",
        "eig_values , eig_vectors = np.linalg.eigh(cov_matrix)\n",
        "sorted_indices = eig_values.argsort()[::-1] \n",
        "eig_values = eig_values[sorted_indices]\n",
        "eig_vectors = eig_vectors[:,sorted_indices]\n",
        "print(eig_values)\n",
        "print(eig_vectors)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CRTuIkLGFFAo"
      },
      "outputs": [],
      "source": [
        "print(eig_values.shape)\n",
        "print(eig_vectors.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNSrwOtGihCx"
      },
      "source": [
        "## Computing number of reduced dimensions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wG_NtvwCDM3X"
      },
      "outputs": [],
      "source": [
        "# number of reduced dimensions\n",
        "reduced_dimensions = []\n",
        "sum_eigen_values = eig_values.sum()\n",
        "for alpha in alpha_values:\n",
        "  current_sum = 0.0\n",
        "  i = 0\n",
        "  while (current_sum/sum_eigen_values)<alpha:\n",
        "      current_sum = current_sum + eig_values[i]\n",
        "      i+=1\n",
        "  reduced_dimensions.append(i)\n",
        "\n",
        "\n",
        "# get U-matrix\n",
        "print(reduced_dimensions)\n",
        "#U_matrix = eig_vectors[:,0:reduced_dimensions[3]]\n",
        "#U_matrices = np.array([U_matrix])\n",
        "#U_matrices = np.append(U_matrices,[U_matrix],axis=0)\n",
        "#print(U_matrices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ve2PpcCl4MN"
      },
      "source": [
        "## Projecting Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kHdhzoICl37v"
      },
      "outputs": [],
      "source": [
        "U_matrix = eig_vectors[:,0:reduced_dimensions[3]]\n",
        "print(U_matrix.shape)\n",
        "projected_training_data = np.dot(centered_ds,U_matrix)\n",
        "train_labels = odd_data_matrix[:,0]\n",
        "print(projected_training_data.shape)\n",
        "centered_testing_data = even_data_matrix[:,1:10305]\n",
        "centered_testing_data = centered_testing_data - centered_testing_data.mean(axis = 0)\n",
        "print(centered_testing_data.shape)\n",
        "projected_testing_data = np.dot(centered_testing_data,U_matrix)\n",
        "test_labels = even_data_matrix[:,0]\n",
        "print(test_labels.shape)\n",
        "print(projected_testing_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQWCy8GTldd3"
      },
      "source": [
        "## Training and testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SB7pp62DPWQF"
      },
      "outputs": [],
      "source": [
        "k_nearest_Neighbours =KNeighborsClassifier(n_neighbors=1)\n",
        "train_labels=train_labels.astype('int')\n",
        "result_k_nearest_Neighbours = k_nearest_Neighbours.fit(projected_training_data,train_labels)\n",
        "predict_for_target_k_nearest = result_k_nearest_Neighbours.predict(projected_testing_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9wvuznyoPWQF"
      },
      "outputs": [],
      "source": [
        "test_labels=test_labels.astype('int')\n",
        "classification_report_result_k_nearest = classification_report(test_labels,predict_for_target_k_nearest)\n",
        "print(classification_report_result_k_nearest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPvHdLafvSmO"
      },
      "source": [
        "## PCA function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C9vv5MkfifKT"
      },
      "outputs": [],
      "source": [
        "def pca(training_set,testing_set,alpha_values,k):\n",
        "  dataset = training_set[:,1:10305]\n",
        "  centered_ds = dataset - dataset.mean(axis = 0)\n",
        "  cov_matrix = np.cov(centered_ds.astype(float).T,ddof=0)\n",
        "  eig_values , eig_vectors = np.linalg.eigh(cov_matrix)\n",
        "  sorted_indices = eig_values.argsort()[::-1] \n",
        "  eig_values = eig_values[sorted_indices]\n",
        "  eig_vectors = eig_vectors[:,sorted_indices]\n",
        "  reduced_dimensions = []\n",
        "  sum_eigen_values = eig_values.sum()\n",
        "  for alpha in alpha_values:\n",
        "    current_sum = 0.0\n",
        "    i = 0\n",
        "    while (current_sum/sum_eigen_values)<alpha:\n",
        "      current_sum = current_sum + eig_values[i]\n",
        "      i+=1\n",
        "    reduced_dimensions.append(i)\n",
        "  \n",
        "  current_sum = 0.0\n",
        "  accuracies = list()\n",
        "  classification_reports = list()\n",
        "  predicted_labels = list()\n",
        "  confusion_matrices = list()\n",
        "  for i in reduced_dimensions:\n",
        "    U_matrix = eig_vectors[:,0:i]\n",
        "    projected_training_data = np.dot(centered_ds,U_matrix)\n",
        "    train_labels = training_set[:,0]\n",
        "    centered_testing_data = testing_set[:,1:10305]\n",
        "    centered_testing_data = centered_testing_data - centered_testing_data.mean(axis = 0)\n",
        "    projected_testing_data = np.dot(centered_testing_data,U_matrix)\n",
        "    test_labels = testing_set[:,0]\n",
        "    k_nearest_Neighbours =KNeighborsClassifier(n_neighbors=k)\n",
        "    train_labels=train_labels.astype('int')\n",
        "    result_k_nearest_Neighbours = k_nearest_Neighbours.fit(projected_training_data,train_labels)\n",
        "    predict_for_target_k_nearest = result_k_nearest_Neighbours.predict(projected_testing_data)\n",
        "    test_labels=test_labels.astype('int')\n",
        "    classification_report_result_k_nearest = classification_report(test_labels,predict_for_target_k_nearest,digits=3)\n",
        "    confusion_matrix_result = confusion_matrix(test_labels,predict_for_target_k_nearest)\n",
        "    accuaracy_result_KNN = accuracy_score(test_labels, predict_for_target_k_nearest)\n",
        "    accuracies.append(accuaracy_result_KNN)\n",
        "    classification_reports.append(classification_report_result_k_nearest)\n",
        "    predicted_labels.append(predict_for_target_k_nearest)\n",
        "    confusion_matrices.append(confusion_matrix_result)\n",
        "    if(len(alpha_values)==1):\n",
        "      return accuaracy_result_KNN, classification_report_result_k_nearest , predict_for_target_k_nearest,confusion_matrix_result\n",
        "  return accuracies, classification_reports , predicted_labels,confusion_matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MN2iwtTmPrOL"
      },
      "outputs": [],
      "source": [
        "def compute_U_matrix(training_set,testing_set,alpha_value):\n",
        "  dataset = training_set[:,1:10305]\n",
        "  centered_ds = dataset - dataset.mean(axis = 0)\n",
        "  cov_matrix = np.cov(centered_ds.astype(float).T,ddof=0)\n",
        "  eig_values , eig_vectors = np.linalg.eigh(cov_matrix)\n",
        "  sorted_indices = eig_values.argsort()[::-1] \n",
        "  eig_values = eig_values[sorted_indices]\n",
        "  eig_vectors = eig_vectors[:,sorted_indices]\n",
        "  #reduced_dimensions = []\n",
        "  sum_eigen_values = eig_values.sum()\n",
        "  current_sum = 0.0\n",
        "  i = 0\n",
        "  while (current_sum/sum_eigen_values)<alpha_value:\n",
        "    current_sum = current_sum + eig_values[i]\n",
        "    i+=1\n",
        "    #reduced_dimensions.append(i)\n",
        "  U_matrix = eig_vectors[:,0:i]\n",
        "  return U_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0cBLgeVzQzN5"
      },
      "outputs": [],
      "source": [
        "def project_datasets(U_matrix,training_set,testing_set):\n",
        "  dataset = training_set[:,1:10305]\n",
        "  centered_ds = dataset - dataset.mean(axis = 0)\n",
        "  centered_testing_data = testing_set[:,1:10305]\n",
        "  centered_testing_data = centered_testing_data - centered_testing_data.mean(axis = 0)\n",
        "  projected_training_data = np.dot(centered_ds,U_matrix)\n",
        "  projected_testing_data = np.dot(centered_testing_data,U_matrix)\n",
        "  \n",
        "  return projected_training_data,projected_testing_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Oc3KYsQYMcYO"
      },
      "outputs": [],
      "source": [
        "def pca_at_K(training_set,testing_set,alpha_value,k):\n",
        "\n",
        "  U_matrix = compute_U_matrix(training_set,testing_set,alpha_value)\n",
        "  \n",
        "  projected_training_data,projected_testing_data = project_datasets(U_matrix,training_set,testing_set)\n",
        "\n",
        "  train_labels = training_set[:,0]\n",
        "  test_labels = testing_set[:,0]\n",
        "  train_labels=train_labels.astype('int')\n",
        "  test_labels=test_labels.astype('int')\n",
        "  accuracies = list()\n",
        "\n",
        "  for i in k:\n",
        "    k_nearest_Neighbours =KNeighborsClassifier(n_neighbors=i)\n",
        "    result_k_nearest_Neighbours = k_nearest_Neighbours.fit(projected_training_data,train_labels)\n",
        "    predict_for_target_k_nearest = result_k_nearest_Neighbours.predict(projected_testing_data)\n",
        "    classification_report_result_k_nearest = classification_report(test_labels,predict_for_target_k_nearest,digits=3)\n",
        "    accuaracy_result_KNN = accuracy_score(test_labels, predict_for_target_k_nearest)\n",
        "    accuracies.append(accuaracy_result_KNN)\n",
        "  return accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFzlk8xjOwzQ"
      },
      "source": [
        "#LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBlp17Q3EiAs"
      },
      "source": [
        "## Calculate Class Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qTtleid2Hmc5"
      },
      "outputs": [],
      "source": [
        "def compute_class_means(number_of_classes,number_of_features,training_data):\n",
        "  class_means=np.empty((number_of_classes,number_of_features))\n",
        "\n",
        "  for i in range(number_of_classes): \n",
        "    class_means[i]=training_data[training_data.iloc[:,0]==i].iloc[:,1:].mean(axis='index').to_numpy()\n",
        "  \n",
        "  return class_means\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh4ix4ZaLp0I"
      },
      "source": [
        "## Calculate Overall Sample Mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "33R6usN8Lde5"
      },
      "outputs": [],
      "source": [
        "def compute_overall_sample_mean(training_data):\n",
        "  overall_sample_mean=training_data.iloc[:,1:].mean(axis='index').to_numpy()\n",
        "  return overall_sample_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FuP7nKhNM28"
      },
      "source": [
        "## Calculate Between-Class Scatter Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FFnG1ya3NKEN"
      },
      "outputs": [],
      "source": [
        "def compute_between_class_scatter(number_of_classes,number_of_features,number_of_class_samples,class_means,overall_sample_mean):\n",
        " \n",
        "\n",
        "  between_class_scatter=np.zeros((number_of_features,number_of_features))\n",
        "\n",
        "  for i in range (number_of_classes):\n",
        "    np.add(between_class_scatter,np.multiply((np.outer(class_means[i]-overall_sample_mean,class_means[i]-overall_sample_mean)),number_of_class_samples[i]),out=between_class_scatter)\n",
        "  \n",
        "  return between_class_scatter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB0-gaJhUrJB"
      },
      "source": [
        "## Calculate Within-Class Scatter Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Dfc6zhRDUrVR"
      },
      "outputs": [],
      "source": [
        "def compute_within_class_scatter(number_of_classes,number_of_features,training_data,class_means):\n",
        "    within_class_scatter=np.zeros((number_of_features,number_of_features))\n",
        "    for i in range(number_of_classes):\n",
        "      centralized_class_data=(training_data[training_data.iloc[:,0]==i].iloc[:,1:]-class_means[i]).to_numpy() \n",
        "      np.add(within_class_scatter,np.matmul(np.transpose(centralized_class_data),centralized_class_data),out=within_class_scatter,casting='unsafe')\n",
        "      gc.collect()\n",
        "    return within_class_scatter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQqDVJ9pgDiU"
      },
      "source": [
        "## Compute Eigenvalues and Eigenvectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FOSMNoK4f0bi"
      },
      "outputs": [],
      "source": [
        "def compute_eigens(number_of_classes,number_of_features,number_of_class_samples,training_data):\n",
        "  class_means=compute_class_means(number_of_classes,number_of_features,training_data)\n",
        "\n",
        "  overall_sample_mean=compute_overall_sample_mean(training_data)\n",
        "\n",
        "  between_class_scatter=compute_between_class_scatter(number_of_classes,number_of_features,number_of_class_samples,class_means,overall_sample_mean)\n",
        "  \n",
        "  within_class_scatter=compute_within_class_scatter(number_of_classes,number_of_features,training_data,class_means)\n",
        "\n",
        "  lda_eigen_values,lda_eigen_vectors=np.linalg.eigh(np.matmul(np.linalg.inv(within_class_scatter),between_class_scatter))\n",
        "  lda_eigen_values=lda_eigen_values.real\n",
        "  lda_eigen_vectors=lda_eigen_vectors.real\n",
        "  sorted_indices = lda_eigen_values.argsort()[::-1] \n",
        "  lda_eigen_values = lda_eigen_values[sorted_indices]\n",
        "  lda_eigen_vectors = lda_eigen_vectors[:,sorted_indices]\n",
        "\n",
        "  return lda_eigen_values,lda_eigen_vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yWpPyh4CBn4"
      },
      "source": [
        "## Compute Projection Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gr5MiOxODnBF"
      },
      "outputs": [],
      "source": [
        "def compute_projection_matrix(eigen_values,eigen_vectors,number_of_features=10304,number_of_dominant_eigen_vectors=39):\n",
        "  \n",
        "\n",
        "\n",
        "  lda_projection_matrix=np.empty((number_of_features,number_of_dominant_eigen_vectors))\n",
        "\n",
        "  for i in range(number_of_dominant_eigen_vectors):\n",
        "    lda_projection_matrix[:,i]=eigen_vectors[:,i].real\n",
        "  lda_projection_matrix=lda_projection_matrix.T\n",
        "\n",
        "  return lda_projection_matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDv9xoKSjPi-"
      },
      "source": [
        "## Projection on The Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ra9XoXTCjPzN"
      },
      "outputs": [],
      "source": [
        "def project_training_set(lda_projection_matrix,training_data):\n",
        "  lda_projected_training_set=np.matmul(lda_projection_matrix,training_data.iloc[:,1:].to_numpy().T).T\n",
        "  return lda_projected_training_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JArERzmyjTe9"
      },
      "source": [
        "## Projection on The Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D6G-gtHPjWB1"
      },
      "outputs": [],
      "source": [
        "def project_testing_set(lda_projection_matrix,testing_data):\n",
        "  lda_projected_testing_set=np.matmul(lda_projection_matrix,testing_data.iloc[:,1:].to_numpy().T).T\n",
        "  return lda_projected_testing_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6TwygTtB5jX"
      },
      "source": [
        "## Project Training and Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q-mg5hDbjD3J"
      },
      "outputs": [],
      "source": [
        "def project_data(lda_projection_matrix,training_data,testing_data):\n",
        "  lda_projected_training_set=project_training_set(lda_projection_matrix,training_data)\n",
        "  lda_projected_testing_set=project_testing_set(lda_projection_matrix,testing_data)\n",
        "  return lda_projected_training_set,lda_projected_testing_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGY-EDsUB2mb"
      },
      "source": [
        "## LDA Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h0r99UoqE61e"
      },
      "outputs": [],
      "source": [
        "def LDA(training_data,testing_data,number_of_class_samples,number_of_classes=40,number_of_features=10304,number_of_dominant_eigen_vectors=39):\n",
        "  \n",
        " \n",
        "\n",
        "  lda_eigen_values,lda_eigen_vectors=compute_eigens(number_of_classes,number_of_features,number_of_class_samples,training_data)\n",
        "\n",
        "  lda_projection_matrix=compute_projection_matrix(lda_eigen_values,lda_eigen_vectors,number_of_features,number_of_dominant_eigen_vectors)\n",
        "\n",
        "  lda_projected_training_set,lda_projected_testing_set=project_data(lda_projection_matrix,training_data,testing_data)\n",
        "\n",
        " \n",
        "  return lda_projected_training_set,lda_projected_testing_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f5WblVV5_aLX"
      },
      "outputs": [],
      "source": [
        "def KNN(n_neighbors,training_labels,testing_labels,lda_projected_training_set,lda_projected_testing_set):\n",
        "  k_nearest_Neighbours =KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "  result_k_nearest_Neighbours = k_nearest_Neighbours.fit(lda_projected_training_set,training_labels)\n",
        "  predict_for_target_k_nearest = result_k_nearest_Neighbours.predict(lda_projected_testing_set)\n",
        "  classification_report_result_k_nearest = classification_report(testing_labels,predict_for_target_k_nearest)\n",
        "  accuracy = accuracy_score(testing_labels,predict_for_target_k_nearest)\n",
        "  return accuracy,classification_report_result_k_nearest,predict_for_target_k_nearest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL8qKGP3CIMO"
      },
      "source": [
        "## LDA Run on 50 50 Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SCOOcoK_DuuE"
      },
      "outputs": [],
      "source": [
        "training_data = pd.DataFrame(odd_data_matrix)\n",
        "testing_data=pd.DataFrame(even_data_matrix)\n",
        "number_of_class_samples=np.full((40), 5, dtype=int)\n",
        "lda_projected_training_set,lda_projected_testing_set=LDA(training_data,testing_data,number_of_class_samples=number_of_class_samples)\n",
        "\n",
        "training_labels=training_data.iloc[:,0]\n",
        "training_labels=training_labels.astype('int')\n",
        "testing_labels=testing_data.iloc[:,0]\n",
        "testing_labels=testing_labels.astype('int')\n",
        "\n",
        "_,classification_report_knn,_=KNN(1,training_labels,testing_labels,lda_projected_training_set,lda_projected_testing_set)\n",
        "print(classification_report_knn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_nYSNiwPt_S"
      },
      "source": [
        "#LDA Classifier Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q9xfwQxzPtsn"
      },
      "outputs": [],
      "source": [
        "parameters=np.array([1,3,5,7])\n",
        "lda_accuracies=np.empty((4))\n",
        "training_labels=training_data.iloc[:,0]\n",
        "training_labels=training_labels.astype('int')\n",
        "testing_labels=testing_data.iloc[:,0]\n",
        "testing_labels=testing_labels.astype('int')\n",
        "index=0\n",
        "for parameter in parameters :\n",
        "  lda_accuracies[index],_,_=KNN(parameter,training_labels,testing_labels,lda_projected_training_set,lda_projected_testing_set)\n",
        "  index+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3D001HveTYWg"
      },
      "outputs": [],
      "source": [
        "plt.plot(parameters,lda_accuracies)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNr-oVWVRum3"
      },
      "source": [
        "#PCA Classifier Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b6egrHu7TL0Y"
      },
      "outputs": [],
      "source": [
        "pca_tuning_accuracies = list()\n",
        "for i in [0.8,0.85,0.9,0.95]:\n",
        "  accuracies = pca_at_K(odd_data_matrix,even_data_matrix,i,[1,3,5,7])\n",
        "  pca_tuning_accuracies.append(accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M6JcId3nTp0v"
      },
      "outputs": [],
      "source": [
        "alphas = [0.8,0.85,0.9,0.95]\n",
        "figure, axis = plt.subplots(2, 2)\n",
        "axis[0, 0].plot(alphas,pca_tuning_accuracies[0] )\n",
        "axis[0, 0].set_title(\"K=1\")\n",
        "\n",
        "axis[0, 1].plot(alphas, pca_tuning_accuracies[1])\n",
        "axis[0, 1].set_title(\"K=3\")\n",
        "  \n",
        "axis[1, 0].plot(alphas,  pca_tuning_accuracies[2])\n",
        "axis[1, 0].set_title(\"K=5\")\n",
        "  \n",
        "axis[1, 1].plot(alphas,  pca_tuning_accuracies[3])\n",
        "axis[1, 1].set_title(\"K=7\")\n",
        "plt.subplots_adjust(hspace=0.8,wspace = 0.8)\n",
        "print(pca_tuning_accuracies[1])\n",
        "print(pca_tuning_accuracies[0])\n",
        "print(pca_tuning_accuracies[2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq9_q0KBdrZ-"
      },
      "source": [
        "# (70-30) Data split comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upkpuwlhd1Uv"
      },
      "source": [
        "## LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6tWXvNg0d0FP"
      },
      "outputs": [],
      "source": [
        "training_data = pd.DataFrame(seventy_data_matrix)\n",
        "testing_data=pd.DataFrame(thirty_data_matrix)\n",
        "number_of_class_samples=np.full((40), 7, dtype=int)\n",
        "lda_projected_training_set,lda_projected_testing_set=LDA(training_data,testing_data,number_of_class_samples=number_of_class_samples)\n",
        "\n",
        "training_labels=training_data.iloc[:,0]\n",
        "training_labels=training_labels.astype('int')\n",
        "testing_labels=testing_data.iloc[:,0]\n",
        "testing_labels=testing_labels.astype('int')\n",
        "\n",
        "_,classification_report_knn,_=KNN(1,training_labels,testing_labels,lda_projected_training_set,lda_projected_testing_set)\n",
        "isNan()\n",
        "print(classification_report_knn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWhvcUPWd3NX"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ONALlnJzM45n"
      },
      "outputs": [],
      "source": [
        "_acc,classification_report_knn,_2 = pca(seventy_data_matrix,thirty_data_matrix,[0.8,0.85,0.9,0.95],1)\n",
        "# for i in classification_report_knn:\n",
        "#   print(i)\n",
        "for i in _acc:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCLErNCvd-rh"
      },
      "source": [
        "#Compare vs Non-Faces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jaXPjx3eg0n"
      },
      "source": [
        "## Generate Faces Vs Non-Faces Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y5C8iPlPeBW5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import PIL\n",
        "an_image = PIL.Image.open(\"/content/drive/MyDrive/prassignment1/s1/1.pgm\")\n",
        "image_sequence = an_image.getdata()\n",
        "image_array = np.array(image_sequence)\n",
        "data_matrix = np.full([10305,1],None)\n",
        "paths=list()\n",
        "for i in range(40):\n",
        "  num_of_file=str(i+1)\n",
        "  path=\"/content/drive/MyDrive/prassignment1/s{}\".format(num_of_file)\n",
        "  for j in range(10):\n",
        "    num_of_image=str(j+1)\n",
        "    full_path=path+\"/\"+num_of_image+\".pgm\"\n",
        "    an_image = PIL.Image.open(full_path)\n",
        "    image_sequence = an_image.getdata()\n",
        "    image_array = np.array(image_sequence)\n",
        "    image_array_labeled = np.insert(image_array,0,0,axis=0)\n",
        "    data_matrix=np.c_[data_matrix,image_array_labeled]\n",
        "    paths.append(full_path)\n",
        "\n",
        "data_matrix=data_matrix[:,1:]\n",
        "data_matrix=np.transpose(data_matrix)\n",
        "for i in range(800): \n",
        "  path=\"/content/drive/MyDrive/nonfaces/ ({}).pgm\".format(i+1)\n",
        "  an_image = PIL.Image.open(path)\n",
        "  image_sequence = an_image.getdata()\n",
        "  image_array = np.array(image_sequence)\n",
        "  image_array_labeled = np.insert(image_array,0,1,axis=0)\n",
        "  data_matrix=np.append(data_matrix,[image_array_labeled],axis=0)\n",
        "  paths.append(path)\n",
        "even_data_matrix=np.full([1,10305],None)\n",
        "odd_data_matrix=np.full([1,10305],None)\n",
        "for i in range(400):\n",
        "  if i%2==0:\n",
        "    even_data_matrix=np.append(even_data_matrix,[data_matrix[i]],axis=0)\n",
        "    even_data_matrix=np.append(even_data_matrix,[data_matrix[i+400]],axis=0)\n",
        "  else:\n",
        "    odd_data_matrix=np.append(odd_data_matrix,[data_matrix[i]],axis=0)\n",
        "    odd_data_matrix=np.append(odd_data_matrix,[data_matrix[i+400]],axis=0)\n",
        "\n",
        "even_data_matrix=np.delete(even_data_matrix,0,0)\n",
        "odd_data_matrix=np.delete(odd_data_matrix,0,0)\n",
        "print(even_data_matrix)\n",
        "print(odd_data_matrix)\n",
        "print(even_data_matrix.shape)\n",
        "print(odd_data_matrix.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-k_fPYtCQFY"
      },
      "source": [
        "##Compute the Accuracy Using A Specific Number of Eigenvectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7-HZMMZdis2n"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(projection_matrix,training_data,testing_data,number_of_class_samples=None):\n",
        " \n",
        "  \n",
        "  lda_projected_training_set,lda_projected_testing_set=LDA(training_data,testing_data,projection_matrix=projection_matrix,number_of_class_samples=number_of_class_samples)\n",
        "  training_labels=training_data.iloc[:,0]\n",
        "  training_labels=training_labels.astype('int')\n",
        "  testing_labels=testing_data.iloc[:,0]\n",
        "  testing_labels=testing_labels.astype('int')\n",
        "  return KNN(1,training_labels,testing_labels,lda_projected_training_set,lda_projected_testing_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EVPra8Y9y07O"
      },
      "outputs": [],
      "source": [
        "def compute_best_projection_matrix(comp_training_data,comp_testing_data,comp_lda_eigen_values,comp_lda_eigen_vectors,number_of_features=10304):\n",
        "  highestAccuracy=0;\n",
        "  noEigenVectors=0;\n",
        "  comp_best_projection_matrix=None\n",
        "  for i in range(10,101,10):\n",
        "    comp_lda_projection_matrix=compute_projection_matrix(eigen_values=comp_lda_eigen_values,eigen_vectors=comp_lda_eigen_vectors,number_of_features=10304,number_of_dominant_eigen_vectors=i)\n",
        "    accuracy,_,_=compute_accuracy(comp_lda_projection_matrix,comp_training_data,comp_testing_data)\n",
        "    print(\"Current Accuracy \",accuracy,\" With \",i,\" Eigen Vectors\")\n",
        "    if(accuracy>highestAccuracy):\n",
        "      highestAccuracy=accuracy;\n",
        "      noEigenVectors=i\n",
        "      comp_best_projection_matrix=comp_lda_projection_matrix\n",
        "    \n",
        "  print(\"The Highest Accuracy Is \",highestAccuracy,\"With \",noEigenVectors,\" Eigen Vectors\")\n",
        "  return comp_best_projection_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eS8j9EKE5oog"
      },
      "outputs": [],
      "source": [
        "even_paths=list()\n",
        "odd_paths=list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0l4eAg_VFLyT"
      },
      "outputs": [],
      "source": [
        "##swicth 1 -> 100 non face\n",
        "##switch 2 -> 200 non face\n",
        "## can be used till switch 8\n",
        "def prepare_data(data_matrix,switch):\n",
        " limit=switch*100\n",
        " even_data_matrix=np.full([1,10305],None)\n",
        " odd_data_matrix=np.full([1,10305],None)\n",
        " for i in range(400):\n",
        "    if i<limit:\n",
        "      if i%2==0:\n",
        "          even_data_matrix=np.append(even_data_matrix,[data_matrix[i]],axis=0)\n",
        "          even_paths.append(paths[i])\n",
        "          even_data_matrix=np.append(even_data_matrix,[data_matrix[i+400]],axis=0)\n",
        "          even_paths.append(paths[i+400])\n",
        "      else:\n",
        "          odd_data_matrix=np.append(odd_data_matrix,[data_matrix[i]],axis=0)\n",
        "          odd_paths.append(paths[i])\n",
        "          odd_data_matrix=np.append(odd_data_matrix,[data_matrix[i+400]],axis=0)\n",
        "          odd_paths.append(paths[i+400])\n",
        "    else:\n",
        "      if i%2==0:\n",
        "          even_data_matrix=np.append(even_data_matrix,[data_matrix[i]],axis=0)\n",
        "          even_paths.append(paths[i])\n",
        "      else:\n",
        "          odd_data_matrix=np.append(odd_data_matrix,[data_matrix[i]],axis=0)\n",
        " if limit==500:\n",
        "    for i in range(100):\n",
        "      if i%2==0:\n",
        "        even_data_matrix=np.append(even_data_matrix,[data_matrix[i+800]],axis=0)\n",
        "        even_paths.append(paths[i+800])\n",
        "      else:\n",
        "        odd_data_matrix=np.append(odd_data_matrix,[data_matrix[i+800]],axis=0)\n",
        " if limit == 600:\n",
        "      for i in range(200):\n",
        "        if i%2==0:\n",
        "          even_data_matrix=np.append(even_data_matrix,[data_matrix[i+800]],axis=0)\n",
        "          even_paths.append(paths[i+800])\n",
        "        else:\n",
        "          odd_data_matrix=np.append(odd_data_matrix,[data_matrix[i+800]],axis=0)\n",
        " if limit == 700:\n",
        "      for i in range(300):\n",
        "        if i%2==0:\n",
        "          even_data_matrix=np.append(even_data_matrix,[data_matrix[i+800]],axis=0)\n",
        "          even_paths.append(paths[i+800])\n",
        "        else:\n",
        "          odd_data_matrix=np.append(odd_data_matrix,[data_matrix[i+800]],axis=0)           \n",
        " if limit == 800:\n",
        "      for i in range(400):\n",
        "        if i%2==0:\n",
        "          even_data_matrix=np.append(even_data_matrix,[data_matrix[i+800]],axis=0)\n",
        "          even_paths.append(paths[i+800])\n",
        "        else:\n",
        "          odd_data_matrix=np.append(odd_data_matrix,[data_matrix[i+800]],axis=0)   \n",
        " even_data_matrix=np.delete(even_data_matrix,0,0)\n",
        " odd_data_matrix=np.delete(odd_data_matrix,0,0)            \n",
        " return even_data_matrix,odd_data_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "akcdBCiYG5eJ"
      },
      "outputs": [],
      "source": [
        "failure_paths=list()\n",
        "accuracies=np.empty((8))\n",
        "classification_reports=list()\n",
        "predicted_labels=list()\n",
        "number_of_class_samples=np.empty((2),dtype=int)\n",
        "number_of_class_samples[0]=200\n",
        "for i in range(1,9,1):\n",
        "  even_data_matrix,odd_data_matrix=prepare_data(data_matrix,i)\n",
        "  failure_paths.append(even_paths)\n",
        "  even_paths=list()\n",
        "  comp_training_data=pd.DataFrame(odd_data_matrix)\n",
        "  comp_testing_data=pd.DataFrame(even_data_matrix)\n",
        "\n",
        "  comp_training_labels=comp_training_data.iloc[:,0]\n",
        "  comp_training_labels=comp_training_labels.astype('int')\n",
        "  comp_testing_labels=comp_testing_data.iloc[:,0]\n",
        "  comp_testing_labels=comp_testing_labels.astype('int')\n",
        "  number_of_class_samples[1]=(i*100)/2\n",
        "\n",
        "  \n",
        "  lda_projected_training_set,lda_projected_testing_set=LDA(comp_training_data,comp_testing_data,number_of_classes=2,number_of_features=10304,number_of_class_samples=number_of_class_samples,number_of_dominant_eigen_vectors=1)\n",
        "  accuracies[i-1],_1,_2=KNN(1,comp_training_labels,comp_testing_labels,lda_projected_training_set,lda_projected_testing_set)\n",
        "  #predicted_labels.append(_2)\n",
        "  classification_reports.append(_1)\n",
        "  confusion_matrix_knn = confusion_matrix(comp_testing_labels,_2)\n",
        "  disp=ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_knn,display_labels=['Faces','NonFaces'])\n",
        "  disp.plot()\n",
        "  plt.show()\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "juSnWVLzpeOP"
      },
      "outputs": [],
      "source": [
        "number_of_nonfaces=[100,200,300,400,500,600,700,800]\n",
        "plt.plot(number_of_nonfaces,accuracies)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DCDhUSVvbjzY"
      },
      "outputs": [],
      "source": [
        "pca_accuracies=list()\n",
        "pca_classification_reports=list()\n",
        "pca_predicted_labels=list()\n",
        "pca_conf_matrices=list()\n",
        "for i in range(1,9,1):\n",
        "  even_data_matrix,odd_data_matrix=prepare_data(data_matrix,i)\n",
        "  nonfaces_pca_acc,_class_report,_pred_labels,conf_matrix=pca(odd_data_matrix,even_data_matrix,[0.8,0.85,0.9,0.95],1)\n",
        "  pca_predicted_labels.append(_pred_labels)\n",
        "  pca_classification_reports.append(_class_report)\n",
        "  pca_conf_matrices.append(conf_matrix)\n",
        "  pca_accuracies.append(nonfaces_pca_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68LwgkDzCbv-"
      },
      "source": [
        "##Plotting the Accuracy vs number of nonfaces while fixing the number of faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hE5wMw_KCg-b"
      },
      "outputs": [],
      "source": [
        "number_of_nonfaces=[100,200,300,400,500,600,700,800]\n",
        "# plt.plot(number_of_nonfaces,pca_accuracies)\n",
        "# plt.show()\n",
        "pca_acc_by_alpha = list()\n",
        "for i in range(4):\n",
        "  current_acc = list()\n",
        "  for j in range(8):\n",
        "    current_acc.append(pca_accuracies[j][i])\n",
        "  pca_acc_by_alpha.append(current_acc)\n",
        "  plt.plot(number_of_nonfaces,current_acc)\n",
        "  plt.show()\n",
        "# print(pca_acc_by_alpha)\n",
        "# print(pca_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NIWF_pO944yL"
      },
      "outputs": [],
      "source": [
        "for i in range(8):\n",
        "  for j in range(4):\n",
        "    disp=ConfusionMatrixDisplay(confusion_matrix=pca_conf_matrices[i][j],display_labels=['Faces','NonFaces'])\n",
        "    disp.plot()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87seLKrMRiT2"
      },
      "source": [
        "##Show Success and Failure Cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhlEoeETbcVR"
      },
      "source": [
        "### LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y7MN9MyjQvEg"
      },
      "outputs": [],
      "source": [
        "failure_casses=list()\n",
        "even_data_matrix,odd_data_matrix=prepare_data(data_matrix,1)\n",
        "comp_training_data=pd.DataFrame(odd_data_matrix)\n",
        "comp_testing_data=pd.DataFrame(even_data_matrix)\n",
        "comp_testing_labels=comp_testing_data.iloc[:,0]\n",
        "comp_testing_labels=comp_testing_labels.astype('int')\n",
        "for i in range(5):\n",
        "  failure_casses.append(np.invert(np.in1d(predicted_labels[i],comp_testing_labels)))\n",
        "for i in range(5):\n",
        "  print('passes of number of non faces {}'.format((i+1)*100))\n",
        "  failure_paths_i=failure_paths[i]\n",
        "  for x in failure_paths_i[failure_casses[i]]:\n",
        "    print(x)  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment #1.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}